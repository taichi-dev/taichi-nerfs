# Taichi NGP Android Demo
Our Android Demo is a semi-finished product at this moment, due to lack of expertise in Android development. 

We support the entire infrastructure from setting up the `camera position` to finally generate the `inferenced image`. However the camera position is directly set in the code, while the inferenced image is written to the disk. To make it a real Demo, consider connecting the camera position with a `Touch Event`, and pass the inferenced image to `Android GUI`.

Please be aware that there are known issues with certain Android devices, which is primarily related to their Vulkan support.

There's also performance optimization opportunities wrt Android deployment. 

**We welcome all contributions to improve the quality of the Android Demo!**

## Prerequisites 
1. Device running Android with Vulkan support
2. Android Studio: https://developer.android.com/studio
3. Android Studio - adb: https://developer.android.com/tools/adb
4. Export ANDROID_NDK_ROOT and ANDROID_SDK_ROOT, for example:
```
export ANDROID_NDK_ROOT=~/Android/Sdk/ndk/25.1.8937393/
export ANDROID_SDK_ROOT=~/Android/Sdk/
```

## Build and Install the Demo
1. Change camera position if neccessary
open `main.cpp` and modify the following lines:
```
float angle_x, angle_y, angle_z = 0.0;
float radius = 2.5;
app.pose_rotate_scale(angle_x, angle_y, angle_z, radius);
```

2. Build and run the inference
```
sh scripts/compile_and_run_nerf.sh
```

3. Checkout the output image
  * You'll notice a `out.png` generated in the same folder, which contains the **inferenced image** with current **camera position**.


## Train and deploy your own NGP model
1. Install Taichi nightly:
  * `python3 -m pip install -i https://pypi.taichi.graphics/simple/ taichi-nightly==1.7.0.post20230523`

It is strongly adviced that you install taichi-nightly versioned `1.7.0.post20230523` since it's in sync with the pre-compiled C-API library shipped in `taichi_c_api_ios_post20230523.zip` or `c_api`. If you'd like to use your customized taichi version, then please recompile C-API library and replace the `c_api` folder accordingly.

2. Train a deployable model
  * Go to the root directory of this repository
  * Modify `scripts/train_nsvf_deploy.sh` as you like
  * Start training process with: `./scripts/train_nsvf_deploy.sh`

A pickle file named `deployment.npy` will be generated by the end of the training process.

3. Generate AOT files with `--model_path`:
  * Feel free to adjust the resolutions with `--res_w` and `res_h`
`python3 InstantNGP/taichi_ngp.py --aot --model_path={PATH_TO_DEPLOYMENT_MODEL}/deployment.npy --res_w=300 --res_h=600`

4. Modify the width and height in C++ code if you've changed `--res_w` or `res_h`:
  * open `main.cpp` and modify the following lines:
```
int img_width  = CUSTOM_WIDTH;
int img_height = CUSTOM_HEIGHT;
app.initialize(img_width, img_height,
               aot_file_root,
               hash_embedding_path,
               sigma_weights_path,
               rgb_weights_path,
               density_bitfield_path,
               pose_path,
               directions_path);
```

5. Install the Demo following steps from **Build and Install the Demo** and have fun!
